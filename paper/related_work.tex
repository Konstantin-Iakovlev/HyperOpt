\section{Related Work}
\textbf{Gradient-Based Hyperaprameter Optimization}. Differentiation through optimization \cite{domke2012generic} was successfully applied to hyperparameter optimization at a large-scale \cite{maclaurin2015gradient}. The unrolled differentiation could be categorized into Forward-Mode and Reverse-Mode differentiation \cite{franceschi2017forward}. The former one suits best for the cases when a handful of hyperparameters is needed to be optimized \cite{micaelli2020non}, for instance, learning rate and weight dacay. The latter is suitable for the setup with millions of hyperparameters while sacrificing the memory consumption when the number of inner optimization steps increases, except for the cases when SGD with momentum is used \cite{maclaurin2015gradient}. Additionally, truncated unrolled differentiation \cite{shaban2019truncated} introduces a trade-off between computational complexity and hypergradient accuracy. However, computations done on truncated trajectories suffer from short horizon bias \cite{wu2018understanding}.

Alternatively, impicit differentiation, inspired by the Implicit Function Theorem (IFT), is used to compute the hypergradient \cite{bengio2000gradient, lorraine2020optimizing, pedregosa2016hyperparameter, luketina2016scalable}.
In \cite{bengio2000gradient} an exact inverse Hessian is computed, which is computationally intractable in huge-scale scenario with millions of model parameters. To sidestep this issue, an approximation is needed. Specifically, the Neumann series approximation \cite{lorraine2020optimizing}, conjugate gradients \cite{pedregosa2016hyperparameter}, GMRES \cite{blondel2022efficient} for solving linear systems, Nystr{\"o}m method \cite{hataya2023nystrom}, and Broyden's method \cite{hao2022bi}. The major limitation is that the near-optimality of the inner optimization is crucial for accurate approximation of the true hypergradient \cite{grazzi2020iteration, blondel2022efficient}. Moreover, the method is inapplicable to tackling the optimizer hyperaprameters such as learning rate.

We summarize the comparison of described approaches in Table \ref{tab:comparison}.


\textbf{Meta-Learning}. Another fundamental application of bilevel optimization is meta-learning \cite{schmidhuber1987evolutionary} (or learning to learn). It aims to train a model that generalizes well over the distribution of tasks \cite{ravi2016optimization}. In the context of gradient-based model-agnostic meta-learning \cite{finn2017model}, the task is to learn an initialization of model parameters such that gradient-based fine-tuning shows good generalization. MAML optimization successfully inherts the methods for hypergradient computation. Specifically,  \cite{li2018learning} successfully employed \cite{luketina2016scalable}, \cite{rajeswaran2019meta} used implicit differentiation with conjugate gradient algorithm.