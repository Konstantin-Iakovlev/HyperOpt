{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d268d8-393e-4b79-947e-aed2ca5baf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/konstantinakovlev/jax-metal/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/konstantinakovlev/jax-metal/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import haiku as hk\n",
    "\n",
    "from clu import metrics\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "from flax import struct, core\n",
    "import optax\n",
    "\n",
    "import jax_dataloader as jdl\n",
    "\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from typing import Callable, Any, List\n",
    "\n",
    "import torch, torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import glob\n",
    "from typing import List, Dict, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 16\n",
    "BIGGER_SIZE = 12\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ba779d-bea7-46f0-87dd-0c7fab7b4423",
   "metadata": {},
   "source": [
    "### Build DARTS cell on Haiku\n",
    "\n",
    "Useful example: https://github.com/deepmind/dm-haiku/blob/main/examples/transformer/model.py\n",
    "\n",
    "\n",
    "## OPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ada59acd-d5c3-4279-bc88-297c2564d2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropPath(hk.Module):\n",
    "    def __init__(self, p=0.0):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, x, is_training=False):\n",
    "        if is_training and self.p > 0:\n",
    "            keep_p = 1.0 - self.p\n",
    "            mask = jax.random.bernoulli(hk.next_rng_key(), keep_p, (x.shape[0], 1, 1, 1))\n",
    "            return x / keep_p * mask\n",
    "        return x\n",
    "\n",
    "\n",
    "class Identity(hk.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def __call__(self, x, is_training=False):\n",
    "        return x\n",
    "\n",
    "\n",
    "class PoolBN(hk.Module):\n",
    "    def __init__(self, pool_type, kernel_size, stride, affine=True):  # C is not needed\n",
    "        super().__init__()\n",
    "        if pool_type.lower() == 'max':\n",
    "            self.pool = hk.MaxPool(window_shape=kernel_size, strides=stride, padding='SAME')\n",
    "        elif pool_type.lower() == 'avg':\n",
    "            self.pool = hk.AvgPool(window_shape=kernel_size, strides=stride, padding='SAME') # TODO: count_include_pad=False\n",
    "        else:\n",
    "            raise ValueError()\n",
    "        self.bn = hk.BatchNorm(affine, affine, 0.9)\n",
    "\n",
    "    def __call__(self, x, is_training):\n",
    "        out = self.pool(x)\n",
    "        out = self.bn(out, is_training)\n",
    "        return out\n",
    "\n",
    "\n",
    "class StdConv(hk.Module):\n",
    "    def __init__(self, C_out, kernel_size, stride, affine=True):  # C_in is not needed\n",
    "        super().__init__()\n",
    "        self.conv = hk.Conv2D(C_out, kernel_shape=kernel_size, stride=stride,\n",
    "                              padding='SAME', with_bias=False)\n",
    "        self.bn = hk.BatchNorm(affine, affine, 0.9)\n",
    "\n",
    "    def __call__(self, x, is_training):\n",
    "        out = jax.nn.relu(x)\n",
    "        out = self.conv(out)\n",
    "        out = self.bn(out, is_training)\n",
    "        return out\n",
    "\n",
    "\n",
    "class FacConv(hk.Module):\n",
    "    \"\"\"\n",
    "    Factorized conv: ReLU - Conv(Kx1) - Conv(1xK) - BN\n",
    "    \"\"\"\n",
    "    def __init__(self, C_in, C_out, kernel_length, stride, affine=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = hk.Conv2D(C_in, kernel_shape=(kernel_length, 1), stride=stride, padding='SAME',\n",
    "                              with_bias=False)\n",
    "        self.conv2 = hk.Conv2D(C_out, kernel_shape=(1, kernel_length), stride=stride, padding='SAME',\n",
    "                               with_bias=False)\n",
    "        self.bn = hk.BatchNorm(affine, affine, 0.9)\n",
    "        \n",
    "    def __call__(self, x, is_training):\n",
    "        out = jax.nn.relu(x)\n",
    "        out = self.conv1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn(out, is_training)\n",
    "        return out\n",
    "\n",
    "\n",
    "class DilConv(hk.Module):\n",
    "    \"\"\"\n",
    "    (Dilated) depthwise separable conv.\n",
    "    ReLU - (Dilated) depthwise separable - Pointwise - BN.\n",
    "    If dilation == 2, 3x3 conv => 5x5 receptive field, 5x5 conv => 9x9 receptive field.\n",
    "    \"\"\"\n",
    "    def __init__(self, C_in, C_out, kernel_size, stride, dilation, affine=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = hk.Conv2D(C_in, kernel_shape=kernel_size, stride=stride, rate=dilation,\n",
    "                               padding='SAME', with_bias=False)\n",
    "        self.conv2 = hk.Conv2D(C_out, kernel_shape=1, stride=1, rate=dilation,\n",
    "                               padding='SAME', with_bias=False)\n",
    "        self.bn = hk.BatchNorm(affine, affine, 0.9)\n",
    "        \n",
    "    def __call__(self, x, is_training):\n",
    "        out = jax.nn.relu(x)\n",
    "        out = self.conv1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn(out, is_training)\n",
    "        return out\n",
    "\n",
    "\n",
    "class SepConv(hk.Module):\n",
    "    \"\"\"\n",
    "    Depthwise separable conv.\n",
    "    DilConv(dilation=1) * 2.\n",
    "    \"\"\"\n",
    "    def __init__(self, C_in, C_out, kernel_size, stride, affine=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = DilConv(C_in, C_out, kernel_size, stride, 1, affine)\n",
    "        self.conv2 = DilConv(C_in, C_out, kernel_size, 1, 1, affine)\n",
    "\n",
    "    def __call__(self, x, is_training):\n",
    "        return self.conv2(self.conv1(x, is_training), is_training)\n",
    "        \n",
    "\n",
    "class FactorizedReduce(hk.Module):\n",
    "    \"\"\"\n",
    "    Reduce feature map size by factorized pointwise (stride=2).\n",
    "    \"\"\"\n",
    "    def __init__(self, C_out, affine=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = hk.Conv2D(C_out // 2, kernel_shape=1, stride=2, padding='VALID', with_bias=False)\n",
    "        self.conv2 = hk.Conv2D(C_out // 2, kernel_shape=1, stride=2, padding='VALID', with_bias=False)\n",
    "        self.bn = hk.BatchNorm(affine, affine, 0.9)\n",
    "\n",
    "    def __call__(self, x, is_training):\n",
    "        out = jax.nn.relu(x)\n",
    "        out = jnp.concatenate([self.conv1(out), self.conv2(out[:, 1:, 1:])], axis=-1)\n",
    "        out = self.bn(out, is_training)\n",
    "        return out\n",
    "        \n",
    "        \n",
    "        \n",
    "### TEST\n",
    "def test_dp():\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    x = jnp.ones((3, 2, 1, 1))\n",
    "    dp = hk.transform(lambda x, is_training: DropPath(0.5)(x, is_training))\n",
    "    params = dp.init(rng, x, True)\n",
    "    assert dp.apply(params, rng, x, True).shape == x.shape\n",
    "\n",
    "\n",
    "def test_id():\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    x = jnp.ones((3, 2, 1, 1))\n",
    "    id_ = hk.transform(lambda x, is_training: Identity()(x, is_training))\n",
    "    params = id_.init(rng, x, True)\n",
    "    assert id_.apply(params, None, x, True).shape == x.shape\n",
    "\n",
    "\n",
    "def test_pool():\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    x = jnp.ones((3, 16, 16, 3))\n",
    "    pool = hk.transform_with_state(lambda x, is_t: PoolBN('avg', 3, 1)(x, is_t))\n",
    "    params, state = pool.init(rng, x, True)\n",
    "    assert pool.apply(params, state, rng, x, True)[0].shape == x.shape  # out, state_new = apply    \n",
    "\n",
    "\n",
    "def test_std_conv():\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    x = jnp.ones((3, 16, 16, 3))\n",
    "    conv = hk.transform_with_state(lambda x, is_t: StdConv(3, 3, 1)(x, is_t))\n",
    "    params, state = conv.init(rng, x, True)\n",
    "    assert conv.apply(params, state, rng, x, True)[0].shape == x.shape  # out, state_new = apply\n",
    "\n",
    "def test_fac_conv():\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    x = jnp.ones((3, 16, 16, 3))\n",
    "    conv = hk.transform_with_state(lambda x, is_t: FacConv(3, 3, 3, 1)(x, is_t))\n",
    "    params, state = conv.init(rng, x, True)\n",
    "    assert conv.apply(params, state, rng, x, True)[0].shape == x.shape  # out, state_new = apply \n",
    "\n",
    "\n",
    "def test_dil_conv():\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    x = jnp.ones((3, 32, 32, 16))\n",
    "    conv = hk.transform_with_state(lambda x, is_t: DilConv(16, 16, 5, 1, 2, False)(x, is_t))\n",
    "    params, state = conv.init(rng, x, True)  # out, state_new = apply\n",
    "    out = conv.apply(params, state, rng, x, True)[0]\n",
    "    assert out.shape == x.shape, f'{out.shape}, {x.shape}'\n",
    "\n",
    "\n",
    "def test_sep_conv():\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    x = jnp.ones((3, 32, 32, 16))\n",
    "    conv = hk.transform_with_state(lambda x, is_t: SepConv(16, 16, 3, 1)(x, is_t))\n",
    "    params, state = conv.init(rng, x, True)\n",
    "    assert conv.apply(params, state, rng, x, True)[0].shape == x.shape  # out, state_new = apply \n",
    "\n",
    "\n",
    "def test_fact_reduce():\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    x = jnp.ones((3, 16, 16, 3))\n",
    "    conv = hk.transform_with_state(lambda x, is_t: FactorizedReduce(4)(x, is_t))\n",
    "    params, state = conv.init(rng, x, True)\n",
    "    out = conv.apply(params, state, rng, x, True)[0]  # out, state_new = apply \n",
    "    assert out.shape == (3, 8, 8, 4), f'{out.shape}'\n",
    "\n",
    "\n",
    "\n",
    "test_dp()\n",
    "test_id()\n",
    "test_pool()\n",
    "test_std_conv()\n",
    "test_fac_conv()\n",
    "test_dil_conv()\n",
    "test_sep_conv()\n",
    "test_fact_reduce()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf16ed5-1fc9-4df9-ad81-82c4d388155a",
   "metadata": {},
   "source": [
    "## Node\n",
    "\n",
    "https://github.com/microsoft/nni/blob/master/examples/nas/legacy/oneshot/darts/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4513a23-06ca-4437-9ef8-32bc84121177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_choice'])\n"
     ]
    }
   ],
   "source": [
    "class LayerChoice(hk.Module):\n",
    "    def __init__(self, channels, stride, label='none'):\n",
    "        super().__init__()\n",
    "        self.label = label\n",
    "        self.ops = {\n",
    "            'maxpool': PoolBN('max', 3, stride, affine=False),\n",
    "            'avgpool': PoolBN('avg', 3, stride, affine=False),\n",
    "            'skipconnect': Identity() if stride == 1 else FactorizedReduce(channels, False),\n",
    "            'sepconv3x3': SepConv(channels, channels, 3, stride, False),\n",
    "            'sepconv5x5': SepConv(channels, channels, 5, stride, False),\n",
    "            'dilconv3x3': DilConv(channels, channels, 3, stride, 2, False),\n",
    "            'dilconv5x5': DilConv(channels, channels, 5, stride, 2, False)\n",
    "        }\n",
    "        \n",
    "    def __call__(self, x, is_training):\n",
    "        \"\"\"x: (bs, w, h, c)\"\"\"\n",
    "        alpha = hk.get_parameter(\"lc_alpha\", shape=(len(self.ops),), init=hk.initializers.RandomNormal(1e-3))\n",
    "        res = jnp.stack([op(x, is_training) for _, op in self.ops.items()], axis=0)  # (# prev, bs, w, h, c)\n",
    "        weights = jax.nn.softmax(alpha, axis=-1).reshape(-1, 1, 1, 1, 1)\n",
    "        return (res * weights).sum(0)\n",
    "\n",
    "\n",
    "class InputChoice(hk.Module):\n",
    "    def __init__(self, n_cand: int, n_chosen: int, label='none'):\n",
    "        super().__init__()\n",
    "        self.n_chosen = n_chosen\n",
    "        self.label = label\n",
    "        self.n_cand = n_cand\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        alpha = hk.get_parameter(\"ic_alpha\", shape=(self.n_cand,), dtype=jnp.float32,\n",
    "                                 init=hk.initializers.RandomNormal(1e-3))\n",
    "        inputs = jnp.stack(inputs, axis=0)  # (#cand, bs, w, h, c)\n",
    "        weights = jax.nn.softmax(alpha, axis=-1).reshape(-1, 1, 1, 1, 1)\n",
    "        return (inputs * weights).sum(0)\n",
    "\n",
    "\n",
    "class Node(hk.Module):\n",
    "    def __init__(self, node_id, num_prev_nodes, channels, num_downsample_connect, drop_path_prob):\n",
    "        super().__init__()\n",
    "        choice_keys = []\n",
    "        self.edges = []\n",
    "        for i in range(num_prev_nodes):\n",
    "            stride = 2 if i < num_downsample_connect else 1\n",
    "            choice_keys.append(f'{node_id}_p{i}')\n",
    "            self.edges.append(LayerChoice(channels, stride, choice_keys[-1]))\n",
    "        self.drop_path = DropPath(drop_path_prob)\n",
    "        self.input_switch = InputChoice(n_cand=len(choice_keys), n_chosen=2, label=f'{node_id}_switch')\n",
    "\n",
    "    def __call__(self, prev_nodes, is_training):\n",
    "        \"\"\"Prev nodes: List [bs, w, h, c]\"\"\"\n",
    "        out = [edge(node, is_training) for edge, node in zip(self.edges, prev_nodes)]\n",
    "        out = [self.drop_path(o, is_training) for o in out]\n",
    "        return self.input_switch(out)\n",
    "\n",
    "\n",
    "### TEST\n",
    "def test_layer_choice():\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    x = jnp.ones((3, 32, 32, 16))\n",
    "    lc = hk.transform_with_state(lambda x, is_t: LayerChoice(16, 1)(x, is_t))\n",
    "    params, state = lc.init(rng, x, True)\n",
    "    # print(params.keys())\n",
    "    out = lc.apply(params, state, rng, x, True)[0]  # out, state_new = apply \n",
    "    assert out.shape == x.shape\n",
    "\n",
    "\n",
    "def test_inp_choice():\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    x = jnp.ones((3, 32, 32, 16))\n",
    "    ic = hk.transform_with_state(lambda y: InputChoice(3, 2)(y))\n",
    "    params, state = ic.init(rng, [x, x, x])\n",
    "    print(params.keys())\n",
    "    out = ic.apply(params, state, rng, [x, x, x])[0]  # out, state_new = apply \n",
    "    assert out.shape == x.shape\n",
    "\n",
    "\n",
    "def test_node():\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    x = jnp.ones((3, 32, 32, 16))\n",
    "    node = hk.transform_with_state(lambda x, t: Node(3, 3, 16, 0, 0.1)(x, t))\n",
    "    params, state = node.init(rng, [x, x, x], True)\n",
    "    out = node.apply(params, state, rng, [x, x, x], True)[0]\n",
    "    assert out.shape == x.shape, f'{out.shape}'\n",
    "\n",
    "\n",
    "test_layer_choice()\n",
    "test_inp_choice()\n",
    "test_node()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46e93e52-c41e-48fc-8939-3618a902f78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cell(hk.Module):\n",
    "    def __init__(self, n_nodes, channels_pp, channels_p, channels, reduction_p, reduction, drop_path_prob):\n",
    "        super().__init__()\n",
    "        self.reduction = reduction\n",
    "        self.n_nodes = n_nodes\n",
    "\n",
    "        if reduction_p:\n",
    "            self.preproc0 = FactorizedReduce(channels, affine=False)\n",
    "        else:\n",
    "            self.preproc0 = StdConv(channels, 1, 1, affine=False)\n",
    "        self.preproc1 = StdConv(channels, 1, 1, affine=False)\n",
    "\n",
    "        # generate dag\n",
    "        self.mutable_ops = []\n",
    "        for depth in range(2, self.n_nodes + 2):\n",
    "            self.mutable_ops.append(Node(f\"{'reduce' if reduction else 'normal'}_n{depth}\",\n",
    "                                         depth, channels, 2 if reduction else 0, drop_path_prob))\n",
    "\n",
    "    def __call__(self, s0, s1, is_training):\n",
    "        inputs = [self.preproc0(s0, is_training), self.preproc1(s1, is_training)]\n",
    "        for node in self.mutable_ops:\n",
    "            out = node(inputs, is_training)\n",
    "            inputs.append(out)\n",
    "        out = jnp.concatenate(inputs[2:], axis=-1)  # (bs, w, h, c * nodes)\n",
    "        return out\n",
    "\n",
    "\n",
    "def test_cell():\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    x = jnp.ones((3, 32, 32, 16))\n",
    "    cell = hk.transform_with_state(lambda x, y, t: Cell(4, 3*16, 3 * 16, 16, False, False, 0.1)(x, y, t))\n",
    "    params, state = cell.init(rng, x, x, True)\n",
    "    out = cell.apply(params, state, rng, x, x, True)[0]\n",
    "    assert out.shape == (3, 32, 32, 64), f'{out.shape}'\n",
    "\n",
    "\n",
    "test_cell()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7a82f3-1be0-4e75-8454-ed7e31c24645",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e196cb62-c5f3-4d98-9588-f5295bd408c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(hk.Module):\n",
    "    def __init__(self, channels, n_classes, n_layers, n_nodes=4,\n",
    "                stem_multiplier=3, drop_path_prob=0.0):\n",
    "        # TODO: add aux if necessary\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.n_classes = n_classes\n",
    "        self.n_layers = n_layers\n",
    "        c_cur = stem_multiplier * self.channels\n",
    "        self.stem = hk.Conv2D(c_cur, 3, stride=1, padding='SAME', with_bias=False)\n",
    "        self.stem_bn = hk.BatchNorm(True, True, 0.9)\n",
    "\n",
    "        # for the first cell, stem is used for both s0 and s1\n",
    "        # [!] channels_pp and channels_p is output channel size, but c_cur is input channel size.\n",
    "        channels_pp, channels_p, c_cur = c_cur, c_cur, channels\n",
    "\n",
    "        self.cells = []\n",
    "        reduction_p, reduction = False, False\n",
    "        for i in range(n_layers):\n",
    "            reduction_p, reduction = reduction, False\n",
    "            # Reduce featuremap size and double channels in 1/3 and 2/3 layer.\n",
    "            if i in [n_layers // 3, 2 * n_layers // 3]:\n",
    "                c_cur *= 2\n",
    "                reduction = True\n",
    "            cell = Cell(n_nodes, channels_pp, channels_p, c_cur, reduction_p, reduction, drop_path_prob)\n",
    "            self.cells.append(cell)\n",
    "            c_cur_out = c_cur * n_nodes\n",
    "            channels_pp, channels_p = channels_p, c_cur_out\n",
    "            \n",
    "        self.linear = hk.Linear(n_classes)\n",
    "\n",
    "\n",
    "    def __call__(self, x, is_training):\n",
    "        s0 = s1 = self.stem_bn(self.stem(x), is_training)\n",
    "        for i, cell in enumerate(self.cells):\n",
    "            # cell(s0, s1)\n",
    "            s0, s1 = s1, cell(s0, s1, is_training)\n",
    "\n",
    "        out = s1.mean(axis=[-1, -2])  # global adaptive pooling\n",
    "        out = out.reshape(out.shape[0], -1)  # flatten\n",
    "        logits = self.linear(out)\n",
    "        return logits\n",
    "\n",
    "def test_cnn():\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "    x = jnp.ones((3, 32, 32, 3))\n",
    "    cnn = hk.transform_with_state(lambda x, t: CNN(16, 10, 1)(x, t))\n",
    "    params, state = cnn.init(rng, x, True)\n",
    "    out = cnn.apply(params, state, rng, x, True)[0]\n",
    "    assert out.shape == (3, 10)\n",
    "\n",
    "\n",
    "test_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f2d48ee-6be3-4629-a86f-d427a751b931",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "x = jnp.ones((3, 32, 32, 3))\n",
    "cnn = hk.transform_with_state(lambda x, t: CNN(16, 10, 1)(x, t))\n",
    "params, state = cnn.init(rng, x, True)\n",
    "out = cnn.apply(params, state, None, x, True)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42403fee-ce4f-46d1-b60f-9511b0d8c4a4",
   "metadata": {},
   "source": [
    "### 1-layer network => do not share parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e621c358-fb3c-4d0f-8fa0-9affdf18ff48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([{'ic_alpha': Array([ 0.00158999, -0.0003824 ], dtype=float32)}, {'lc_alpha': Array([-0.00039745,  0.00262213, -0.00046866,  0.00169459,  0.00027594,\n",
       "        0.00163345, -0.00016987], dtype=float32)}, {'lc_alpha': Array([-0.00011725, -0.00021481, -0.0002148 , -0.00189549, -0.00110976,\n",
       "        0.00219348,  0.00024185], dtype=float32)}, {'ic_alpha': Array([ 0.00077681, -0.00016473, -0.0002152 ], dtype=float32)}, {'lc_alpha': Array([-0.00129291, -0.00086983,  0.00018381,  0.00123449,  0.00072178,\n",
       "        0.0011726 , -0.00187813], dtype=float32)}, {'lc_alpha': Array([-0.00066265,  0.00143617, -0.0008633 , -0.001704  , -0.00163068,\n",
       "        0.00021376,  0.00086577], dtype=float32)}, {'lc_alpha': Array([ 0.00083637, -0.00041961, -0.0019002 , -0.00166142, -0.00178719,\n",
       "       -0.00059523,  0.00122192], dtype=float32)}, {'ic_alpha': Array([-0.00189897, -0.00062385, -0.00120795,  0.00092347], dtype=float32)}, {'lc_alpha': Array([ 0.00067808, -0.00017294,  0.00027677,  0.0011895 ,  0.00136863,\n",
       "       -0.00017513, -0.00074789], dtype=float32)}, {'lc_alpha': Array([ 0.00033506, -0.00177405, -0.00067666, -0.0013877 ,  0.0005867 ,\n",
       "        0.00071412,  0.00069788], dtype=float32)}, {'lc_alpha': Array([ 0.00086902, -0.00018407,  0.00016538,  0.00127223,  0.0007007 ,\n",
       "        0.00056835,  0.00192441], dtype=float32)}, {'lc_alpha': Array([-5.6094788e-05,  2.9816531e-04,  1.6715542e-04, -4.3988967e-04,\n",
       "       -1.3141103e-04,  1.5671873e-04,  1.0789896e-03], dtype=float32)}, {'ic_alpha': Array([ 7.6457771e-04, -5.4779182e-05,  2.9192970e-04,  4.0215300e-04,\n",
       "        1.6530056e-03], dtype=float32)}, {'lc_alpha': Array([-0.00052262, -0.00021769, -0.00079446, -0.00116417, -0.00113388,\n",
       "        0.00050822,  0.00071892], dtype=float32)}, {'lc_alpha': Array([-4.3458171e-04, -7.8727450e-04,  9.5970667e-05,  4.8888265e-04,\n",
       "        3.6048013e-04, -3.1567362e-04,  8.4898830e-04], dtype=float32)}, {'lc_alpha': Array([-8.9276483e-04,  1.2304831e-03,  7.7024197e-05, -4.7029171e-04,\n",
       "        3.4982042e-04, -6.2994304e-04,  5.5922038e-04], dtype=float32)}, {'lc_alpha': Array([ 3.4475679e-04,  1.9359753e-04,  8.0324928e-05, -8.7835116e-04,\n",
       "       -7.1849812e-05,  6.3893765e-07, -1.8287663e-03], dtype=float32)}, {'lc_alpha': Array([ 3.1528060e-04, -4.1668358e-05,  9.9074282e-04, -4.4925584e-04,\n",
       "        9.0255495e-04,  2.6210991e-03, -5.4848380e-04], dtype=float32)}])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_params, h_params = hk.data_structures.partition(lambda m, n, p: 'alpha' not in n, params)\n",
    "h_params.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff31d389-0350-47fe-85a6-381fc246f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import graphviz\n",
    "# dot = hk.experimental.to_dot(cnn.apply)(params, state, rng, x, True)\n",
    "# src = graphviz.Source(dot)\n",
    "# src.render('cnn', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50f53b65-3fa1-435d-aec7-07fb492abc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, i in enumerate(hk.experimental.eval_summary(lambda x: cnn.apply(params, state, rng, x, True))(x)):\n",
    "#     print(\"mod := {:14} | in := {} out := {}\".format(i.module_details.module.module_name,\n",
    "#                                                      i.args_spec[0], i.output_spec))\n",
    "#     if idx >= 10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc0d245-29cc-4d6c-8588-29b24d83a7c8",
   "metadata": {},
   "source": [
    "## Bilevel state and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e72d767c-ebd2-4f0e-ba14-d7c695ea41ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class Metrics(metrics.Collection):\n",
    "    accuracy: metrics.Accuracy\n",
    "    loss: metrics.Average.from_output('loss')\n",
    "\n",
    "\n",
    "class NasTrainState(struct.PyTreeNode):\n",
    "    rng: jax.Array\n",
    "    metrics: Metrics\n",
    "    step: int\n",
    "    apply_fn: Callable = struct.field(pytree_node=False)\n",
    "    w_params: core.FrozenDict[str, Any] = struct.field(pytree_node=True)\n",
    "    h_params: core.FrozenDict[str, Any] = struct.field(pytree_node=True)\n",
    "    bn_state: core.FrozenDict[str, Any] = struct.field(pytree_node=True)\n",
    "    inner_opt: optax.GradientTransformation = struct.field(pytree_node=False)\n",
    "    inner_opt_state: optax.OptState = struct.field(pytree_node=True)\n",
    "    outer_opt: optax.GradientTransformation = struct.field(pytree_node=False)\n",
    "    outer_opt_state: optax.OptState = struct.field(pytree_node=True)\n",
    "    lr: float  # inner lr\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, *, apply_fn, w_params, h_params, bn_state, inner_opt, outer_opt, **kwargs):\n",
    "        inner_opt_state = inner_opt.init(w_params)\n",
    "        outer_opt_state = outer_opt.init(h_params)\n",
    "        return cls(\n",
    "            step=0,\n",
    "            apply_fn=apply_fn,\n",
    "            w_params=w_params,\n",
    "            h_params=h_params,\n",
    "            bn_state=bn_state,\n",
    "            inner_opt=inner_opt,\n",
    "            outer_opt=outer_opt,\n",
    "            inner_opt_state=inner_opt_state,\n",
    "            outer_opt_state=outer_opt_state,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def apply_w_gradients(self, *, w_grads, **kwargs):\n",
    "        updates, new_inn_state = self.inner_opt.update(w_grads, self.inner_opt_state, self.w_params)\n",
    "        new_params = optax.apply_updates(self.w_params, updates)\n",
    "        rng, _ = jax.random.split(self.rng)\n",
    "        return self.replace(\n",
    "            step=self.step + 1,\n",
    "            w_params=new_params,\n",
    "            inner_opt_state=new_inn_state,\n",
    "            rng=rng,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def apply_h_gradients(self, *, h_grads, **kwargs):\n",
    "        updates, new_out_state = self.outer_opt.update(h_grads, self.outer_opt_state, self.h_params)\n",
    "        new_params = optax.apply_updates(self.h_params, updates)\n",
    "        return self.replace(\n",
    "            step=self.step + 1,\n",
    "            h_params=new_params,\n",
    "            outer_opt_state=new_out_state,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "\n",
    "def create_nas_train_state(module, rng, learning_rate=0.025, momentum=0.9, w_decay=3e-4,\n",
    "                               alpha_lr=1e-4, alpha_decay=1e-3):\n",
    "    \"\"\"Creates an initial `TrainState`.\"\"\"\n",
    "    params, bn_state = module.init(rng, jnp.ones([1, 32, 32, 3]), True)\n",
    "    w_params, h_params = hk.data_structures.partition(lambda m, n, p: 'alpha' not in n, params)\n",
    "    tx_inner = optax.chain(optax.add_decayed_weights(w_decay),\n",
    "                           optax.sgd(learning_rate, momentum=momentum))\n",
    "    tx_outer = optax.chain(optax.add_decayed_weights(alpha_decay), optax.adam(alpha_lr, b1=0.5, b2=0.999))\n",
    "    return NasTrainState.create(\n",
    "      apply_fn=module.apply, w_params=w_params, h_params=h_params, bn_state=bn_state, inner_opt=tx_inner, outer_opt=tx_outer,\n",
    "      metrics=Metrics.empty(), lr=learning_rate, rng=rng)\n",
    "\n",
    "\n",
    "\n",
    "conv_net = hk.transform_with_state(lambda x, t: CNN(16, 10, 1, drop_path_prob=0.1)(x, t))\n",
    "rng = jax.random.PRNGKey(42)\n",
    "state = create_nas_train_state(conv_net, jax.random.PRNGKey(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d71df44-ff2c-4c7b-9194-82c5ab704cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def proc(st):\n",
    "#     st = st.replace(bn_state=jax.tree_util.tree_map(jnp.zeros_like, st.bn_state))\n",
    "#     print(st.bn_state['cnn/~/batch_norm/~/mean_ema'])\n",
    "\n",
    "# print(state.bn_state['cnn/~/batch_norm/~/mean_ema'])\n",
    "# proc(state)\n",
    "# print(state.bn_state['cnn/~/batch_norm/~/mean_ema'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc06c1da-05de-49f2-b6e6-215e7894a6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(x.size for x in jax.tree_util.tree_leaves(state.w_params)) // 1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a096b957-52f7-4cf6-a7ac-6028a51dd44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def foo(x):\n",
    "#     return x ** 2, 123\n",
    "\n",
    "# jax.value_and_grad(foo, has_aux=True)(6.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d7917b-99ba-44d5-b95f-e07076f8fc29",
   "metadata": {},
   "source": [
    "### Dataset: Cifar10, only train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d14191e-df38-48b5-83b0-1894b3c51ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "CIFAR_MEAN = [0.49139968, 0.48215827, 0.44653124]\n",
    "CIFAR_STD = [0.24703233, 0.24348505, 0.26158768]\n",
    "\n",
    "class ToNumpy:\n",
    "  def __call__(self, pic):\n",
    "    return np.asarray(pic.permute(1, 2, 0), dtype=np.float32)\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CIFAR_MEAN, CIFAR_STD),\n",
    "    ToNumpy(),\n",
    "  ])\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(root='.', train=True, download=True, transform=train_transform)\n",
    "\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(0.5 * num_train))\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#   train_data, batch_size=64,\n",
    "#   sampler=torch.utils.data.sampler.SubsetRandomSampler(indices[:split]),\n",
    "#   pin_memory=True, num_workers=2)\n",
    "\n",
    "train_loader = jdl.DataLoader(torch.utils.data.Subset(train_data, range(split)), 'pytorch',\n",
    "                              batch_size=64, shuffle=True, drop_last=True)\n",
    "\n",
    "# valid_loader = torch.utils.data.DataLoader(\n",
    "#   train_data, batch_size=64,\n",
    "#   sampler=torch.utils.data.sampler.SubsetRandomSampler(indices[split:num_train]),\n",
    "#   pin_memory=True, num_workers=2)\n",
    "\n",
    "valid_loader = jdl.DataLoader(torch.utils.data.Subset(train_data, range(split, num_train)), 'pytorch',\n",
    "                             batch_size=64, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b1baea2-b726-4fef-92df-9239f989d568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 32, 32, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42654006-d9f2-4b0a-8df3-2f2db0b8ac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def loss_fn(w_params, h_params, state, batch, is_training=True):\n",
    "    params = hk.data_structures.merge(w_params, h_params)\n",
    "    logits, bn_state = state.apply_fn(params, state.bn_state, state.rng,\n",
    "                                          batch['image'], is_training)\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(\n",
    "        logits=logits, labels=batch['label']).mean()\n",
    "    return loss, state.replace(bn_state=bn_state)\n",
    "\n",
    "@jax.jit\n",
    "def compute_metrics(*, state, batch):\n",
    "    params = hk.data_structures.merge(state.w_params, state.h_params)\n",
    "    logits, _ = state.apply_fn(params, state.bn_state, None, batch['image'], False)\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=batch['label']).mean()\n",
    "    metric_updates = state.metrics.single_from_model_output(logits=logits, labels=batch['label'], loss=loss)\n",
    "    metrics = state.metrics.merge(metric_updates)\n",
    "    state = state.replace(metrics=metrics)\n",
    "    return state\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def inner_step(state: NasTrainState, batch):    \n",
    "    grad_fn = jax.value_and_grad(loss_fn, argnums=0, has_aux=True)\n",
    "    (_, state), grads = grad_fn(state.w_params, state.h_params, state, batch)\n",
    "    state = state.apply_w_gradients(w_grads=grads)\n",
    "    return state\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def B_jvp(w_params, h_params, batch, state, v, eps=1e-7):\n",
    "    \"\"\"d^2 L1 / dl dw v\"\"\"\n",
    "    w_plus = jax.tree_util.tree_map(lambda x, y: x + eps * y, w_params, v)\n",
    "    w_minus = jax.tree_util.tree_map(lambda x, y: x - eps * y, w_params, v)\n",
    "    dl_dlam = jax.grad(loss_fn, argnums=1, has_aux=True)\n",
    "    g_plus = dl_dlam(w_plus, h_params, state, batch)\n",
    "    g_minus = dl_dlam(w_minus, h_params, state, batch)\n",
    "    return jax.tree_util.tree_map(lambda x, y: -state.lr * (x - y) / (2 * eps), g_plus, g_minus)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def A_jvp(w_params, batch, state, v, eps=1e-7):\n",
    "    w_plus = jax.tree_util.tree_map(lambda x, y: x + eps * y, w_params, v)\n",
    "    w_minus = jax.tree_util.tree_map(lambda x, y: x - eps * y, w_params, v)\n",
    "    dl_dw = jax.grad(loss_fn, argnums=0, has_aux=True)\n",
    "    g_plus = dl_dw(w_plus, state.h_params, state, batch)\n",
    "    g_minus = dl_dw(w_minus, state.h_params, state, batch)\n",
    "    hvp = jax.tree_util.tree_map(lambda x, y: (x - y) / (2 * eps), g_plus, g_minus)\n",
    "    return jax.tree_util.tree_map(lambda x, y: x - state.lr * y, v, hvp)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def fo_grad(state, val_batch):\n",
    "    return jax.grad(loss_fn, argnums=1, has_aux=True)(state.w_params, state.h_params, state, val_batch)[0]\n",
    "\n",
    "\n",
    "def drmad_grad(state, batches, val_batch):\n",
    "    \"\"\"T = len(batches)\"\"\"\n",
    "    T = len(batches)\n",
    "    g_so = jax.tree_util.tree_map(jnp.zeros_like, state.h_params)\n",
    "    w_0 = state.w_params\n",
    "    for step, batch in enumerate(batches):\n",
    "        state = inner_step(state, batch)\n",
    "    w_T = state.w_params\n",
    "    alpha = jax.grad(loss_fn, argnums=0)(state.w_params, state.h_params, state, val_batch)\n",
    "    for step, batch in enumerate(batches[::-1]):\n",
    "        t = T - step\n",
    "        w_tm1 = jax.tree_util.tree_map(lambda x, y: (1 - (t - 1) / T) * x + (t - 1) / T * y, w_0, w_T)\n",
    "        g_so = jax.tree_util.tree_map(lambda x, y: x + y, B_jvp(w_tm1, state.h_params, batch, state, alpha), g_so)\n",
    "        # update alpha\n",
    "        alpha = A_jvp(w_tm1, batch, state, alpha)\n",
    "    return state, g_so\n",
    "\n",
    "\n",
    "def proposed_so_grad(state, batches, val_batch, gamma):\n",
    "    \"\"\"T = len(batches)\"\"\"\n",
    "    g_so = jax.tree_util.tree_map(jnp.zeros_like, state.h_params)\n",
    "    T = len(batches)\n",
    "    for step, batch in enumerate(batches):\n",
    "        new_state = inner_step(state, batch)\n",
    "        curr_alpha = jax.grad(loss_fn, argnums=0)(new_state.w_params, state.h_params, state, val_batch)\n",
    "        g_so = jax.tree_util.tree_map(lambda x, y: x * gamma ** (T - 1 - step) + y,\n",
    "                                      B_jvp(state.w_params, state.h_params, batch,\n",
    "                                            state, curr_alpha),\n",
    "                                     g_so)\n",
    "        state = new_state\n",
    "    return state, g_so\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d4e43f7-a6ef-4727-8082-d8e7f3d4af4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [11:24<00:00,  3.42s/it]\n"
     ]
    }
   ],
   "source": [
    "seeds=(0,)\n",
    "\n",
    "\n",
    "# TODO: deal with new bn state on validation. Should we update it? In the original DARTS we do\n",
    "T = 1\n",
    "# method = 'proposed'; gamma=0.001\n",
    "# method = 'DrMAD'\n",
    "method = 'fo'\n",
    "\n",
    "metrics_history = {seed: {'train_loss': [],\n",
    "                   'train_accuracy': [],\n",
    "                   'test_loss': [],\n",
    "                   'test_accuracy': []} for seed in seeds}\n",
    "\n",
    "# TODO: swithc to bigger setup\n",
    "conv_net = hk.transform_with_state(lambda x, t: CNN(4, 10, 1, drop_path_prob=0.1)(x, t))  # 16 channels\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f'Seed: {seed}')\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    state = create_nas_train_state(conv_net, jax.random.PRNGKey(seed))\n",
    "\n",
    "    for outer_step in tqdm(range(200)):\n",
    "        \n",
    "        x_val, y_val = next(iter(valid_loader))\n",
    "        val_batch = {'image': jnp.asarray(x_val), 'label': jnp.asarray(y_val)}\n",
    "        batches = []\n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "            if i >= T:\n",
    "                break\n",
    "            batches.append({'image': jnp.asarray(x), 'label': jnp.asarray(y)})\n",
    "        if method == 'proposed':\n",
    "            state, g_so = proposed_so_grad(state, batches, val_batch, gamma)\n",
    "        elif method == 'fo':\n",
    "            for batch in batches:\n",
    "                state = inner_step(state, batch)\n",
    "            g_so = jax.tree_util.tree_map(jnp.zeros_like, state.h_params)\n",
    "        elif method == 'DrMAD':\n",
    "            state, g_so = drmad_grad(state, batches, val_batch)\n",
    "        else:\n",
    "            raise ValueError('Unknown ' + method)\n",
    "\n",
    "        \n",
    "        g_fo = fo_grad(state, val_batch)\n",
    "        state = state.apply_h_gradients(h_grads=jax.tree_util.tree_map(lambda x, y: x + y, g_fo, g_so))\n",
    "\n",
    "        # eval\n",
    "        if outer_step % 20 == 0 and outer_step > 0:\n",
    "            for x, y in valid_loader:\n",
    "                val_batch = {'image': jnp.asarray(x), 'label': jnp.asarray(y)}\n",
    "                state = compute_metrics(state=state, batch=val_batch)\n",
    "            for metric,value in state.metrics.compute().items():\n",
    "                metrics_history[seed][f'test_{metric}'].append(value.item())\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "935c62ca-ceb5-4923-8ffd-7ed7737c7c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18919159])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_arr = np.stack([metrics_history[s]['test_accuracy'] for s in seeds], axis=0)\n",
    "plt.plot(acc_arr.mean(0))\n",
    "plt.fill_between(range(acc_arr.shape[1]), acc_arr.mean(0) - acc_arr.std(0), acc_arr.mean(0) + acc_arr.std(0), alpha=0.3)\n",
    "\n",
    "acc_arr.max(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21401f5-afdd-4c27-824b-414d599da193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
